# -*- coding: utf-8 -*-
"""Diabetes _Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_QcN4sgJV4QrGpa4Xj7YsnydE-lCPNbd
"""

!pip install -q pyspark

# Import pacakges

from pyspark import SparkContext, SparkConf
from pyspark.sql import SparkSession

import pyspark.sql.functions as F
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Initiate Spark Session
conf = SparkConf().setAppName("PredictiBetes")
sc = SparkContext.getOrCreate(conf=conf)
spark = SparkSession.builder.getOrCreate()

sqlContext = SparkSession.builder\
        .master("local")\
        .appName("Colab")\
        .config('spark.ui.port', '4050')\
        .getOrCreate()

"""**Read File**"""

diabetes_dataset = spark.read.csv('/content/diabetes.csv',sep=',', inferSchema=True, header=True)

diabetes_dataset.head(10)

diabetes_dataset.show(10)

diabetes_dataset.describe().show()

diabetes_dataset.printSchema()

print(type(diabetes_dataset))

diabetes_dataset.groupBy('outcome').count().show()

pd.DataFrame(diabetes_dataset.dtypes, columns = ['Column Name','Data type'])

# Convert df to Pandas
diabetes_data = diabetes_dataset.toPandas()

#Desribing the dataset after converting it to pandas dataframe
diabetes_data.describe()

# Plot each column using bar plot
fig = plt.figure(figsize=(20,10))
title = fig.suptitle("Attribute Distribution", fontsize=30, verticalalignment="center")
for col, num in zip(diabetes_data.describe().columns, range(1,9)):
  axis = fig.add_subplot(3,4, num)
  axis.bar(diabetes_data.index, diabetes_data[col]) #color="blue", alpha=0.35) #edgecolors="skyblue")
  plt.title(col, fontsize=12)

fig.subplots_adjust(hspace=0.4)

"""###Rectifying Null Values"""

diabetes_data.isnull().sum()

"""#####Based on the above output, we can say that, in the dataset, we are reffering to, there are no null values.

###Outlier Detection
"""

fig, axes = plt.subplots(nrows = 2, ncols=4, figsize=(15, 10))

#removing the 'outcome' column from the dataset and taking the rest of the columns
df_cols = diabetes_data.columns[:-1]
axes = axes.ravel()

#plotting the boxplots to rectify the outliers
for col, ax in zip(df_cols, axes):
  sns.boxplot(data=diabetes_data, y=col, ax=ax)
  ax.set(title=f'{col} outliers', xlabel=None)

fig.tight_layout()
plt.show()

#detect outliers using IQR
import numpy as np
outliers_up = list()
outliers_down = list()

def retrive_outliers(column_name, lower_bound_list, upper_bound_list, lower_bound, upper_bound):
  '''
  This function is replacing the ouliers using Interquartile Range Method
  Inputs:
  @column_name = This is the name of the column from which we have to replace the outliers
  @lower_bound_list = This is the list of the lower bounds taken from get_outliers()
  @upper_bound_list = This is the list of the upper bounds taken from get_outliers()
  @lower_bound = This is the of the lower bound value taken from get_outliers()
  @upper_bound = This is the of the upper bound value taken from get_outliers()
  '''
  diabetes_data[column_name].replace(lower_bound_list,lower_bound,inplace=True)
  diabetes_data[column_name].replace(upper_bound_list,upper_bound,inplace=True)

def get_outliers(data):
    '''
    This function is using the typical outlier finder method to get the outliers from the database.
    Method used: Interquartile Range i.e. IQR
    Input:
      @data = It is a dataframe which has the diabetes related data taken from given CSV.
    Output:
    This function returns 2 lists which consists outliers above the upper bound and Outliers below the lower bound.
    '''
    #get the Q1 and Q3
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)

    #find the Interquartile Range
    IQR = q3-q1

    #Calculate the Lower bound and the Upper Bound
    lwr_bound = q1-(1.5*IQR)
    upr_bound = q3+(1.5*IQR)

    #finding the Outliers
    for i in data:
        if (i<lwr_bound):
            outliers_down.append(i)
        elif (i>upr_bound):
            outliers_up.append(i)

    return outliers_up, outliers_down, lwr_bound, upr_bound

#printing outliers with IQR Method
col=diabetes_data[:-1]
for c in col:
    ret_vals = get_outliers(diabetes_data[c])
    print(f"Outliers using Interquartile Range Method: \nColumn_Name:{c} \nOutliers_Upper_Bound:{ret_vals[0]} \nOutliers_Lower_Bound:{ret_vals[1]}")

    #replacing the outliers
    retrive_outliers(c, ret_vals[1], ret_vals[0], ret_vals[2], ret_vals[3])

    #clearing the lists
    outliers_up.clear()
    outliers_down.clear()

"""###Replacing the Zero Values with Mean values"""

cols = diabetes_data[:]
for col in cols:
  diabetes_data[col].replace(0, diabetes_data[col].mean())

"""###Plotting the data after removal of the outliers"""

fig, axes = plt.subplots(nrows = 2, ncols=4, figsize=(15, 10))

#removing the 'outcome' column from the dataset and taking the rest of the columns
df_cols = diabetes_data.columns[:-1]
axes = axes.ravel()

#plotting the boxplots to rectify the outliers
for col, ax in zip(df_cols, axes):
  sns.boxplot(data=diabetes_data, y=col, ax=ax)
  ax.set(title=f'{col} outliers', xlabel=None)

fig.tight_layout()
plt.show()

# Plot each column using bar plot
fig = plt.figure(figsize=(20,10))
title = fig.suptitle("Attribute Distribution", fontsize=30, verticalalignment="center")
for col, num in zip(diabetes_data.describe().columns, range(1,9)):
  axis = fig.add_subplot(3,4, num)
  axis.bar(diabetes_data.index, diabetes_data[col])
  plt.title(col, fontsize=12)

fig.subplots_adjust(hspace=0.4)

"""###Displaying the Correlation Matrix for the data"""

#getting the correlation matrix
diabetes_data.corr()

#Plotting the correlation matrix using seaborn
sns.heatmap(diabetes_data.corr(), cmap='bwr', cbar=True, annot=True)

diabetes_data.sort_index()

"""###Split the Data into Train and Test Data"""

from sklearn.model_selection import train_test_split

X = diabetes_data.drop('Outcome', axis = 1)
Y = diabetes_data['Outcome']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

"""###Scale Data"""

from sklearn.preprocessing import StandardScaler

scale = StandardScaler()

scaled_X_train = scale.fit_transform(X_train)
scaled_X_test = scale.fit_transform(X_test)

scaled_X_train.shape, scaled_X_test.shape

diabetes_data.groupby('Outcome')['Outcome'].count()

"""###Model training

Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

LR_model = LogisticRegression(max_iter=1000)

LR_model.fit(X_train, Y_train)

predictions = LR_model.predict(X_test)

from sklearn.metrics import classification_report
from sklearn.metrics import *

accuracy = accuracy_score(Y_test, predictions)
print(f'Accuracy of Logistic Regression on test data is : {round(accuracy*100)}%')

print(classification_report(Y_test, predictions))

confusion_matrix(Y_test, predictions)

"""Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier

rfc = RandomForestClassifier(n_estimators=200)

rfc.fit(X_train, Y_train)

rfc_predictions = rfc.predict(X_test)

accuracy = accuracy_score(Y_test, rfc_predictions)
print(f'Accuracy of Random Forest Classifier on test data is : {round(accuracy*100)}%')

print(confusion_matrix(Y_test, rfc_predictions))

print(classification_report(Y_test, rfc_predictions))

